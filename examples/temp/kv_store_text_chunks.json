{
  "chunk-1ca67301c9ba9a4ee672f1b0a1c3f674": {
    "tokens": 1200,
    "content": "# Analyzing Collaborative Challenges And Needs Of Ux ![0_Image_0.Png](0_Image_0.Png) Practitioners When Designing With Ai/Ml MEENA DEVII MURALIKUMAR, Human Centered Design & Engineering, University of Washington, USA DAVID W. MCDONALD, Human Centered Design & Engineering, University of Washington, USA UX designers and researchers who work with AI/ML face different kinds of challenges throughout the design process. Though close collaborations with AI/ML developers and data scientists could address some of these challenges, such interdisciplinary collaborations are non-routine and hard to realize. In this work, we investigate barriers for effective collaboration with ML practitioners, how they affect UX practice of AI/ML applications, and what UX practitioners need to overcome these challenges. We conducted a qualitative study with 14 UX practitioners who are working on AI/ML products as designers or researchers. Our findings show that UX practitioners face challenges in communication, understanding the model and model development processes, establishing ways to collaborate, and reconciling model-centric metrics of evaluation with usercentric outcomes. They described various needs in terms of more visibility into model development processes, access to comprehensible and contextual model information, and hypothetical tools that can potentially support collaboration with ML practitioners and enhance UX design processes. We discuss implications of this research for designing collaborative tools and empowering UX practitioners. CCS Concepts: - Human-centered computing → **Empirical studies in collaborative and social computing**. Additional Key Words and Phrases: UX practitioners, collaboration, ML practitioners, AI/ML development ACM Reference Format: Meena Devii Muralikumar and David W. McDonald. 2024. Analyzing Collaborative Challenges and Needs of UX Practitioners when Designing with AI/ML. *Proc. ACM Hum.-Comput. Interact.* 8, CSCW2, Article 447 (November 2024), 25 pages. https://doi.org/10.1145/3686986 ## 1 Introduction The application of Artificial Intelligence (AI) and Machine Learning (ML) algorithms in different kinds of products have become prevalent and commonplace today. AI and ML are umbrella terms to describe algorithms capable of predicting future outcomes, image recognition, speech recognition, and natural language understanding and classification. These algorithms empower a range of interactions and have found its way in influencing how people interact with their social network, make choices, and automate tasks [1]. Despite the vast application of AI and ML, their idiosyncrasies present significant challenges of learnability [42], usability[3], and control [39] for the end-user. In some domains, it can also have more serious implications for ensuring trust, fairness, and ethical use [2, 8]. While some prior HCI and CSCW research studies seek to study end-users and inform the design of a particular type of AI/ML application [15], other studies have examined work practices Authors' Contact Information: Meena Devii Muralikumar, Human Centered Design & Engineering, University of Washington, USA, mmeena@uw.edu; David W. McDonald, Human Centered Design & Engineering, University of Washington, USA, dwmc@uw.edu. of professionals who develop AI/ML systems to understand more generic and systemic challenges [19, 35, 43, 53, 56]. Our work falls in the latter category and specifically focuses on UX practitioners because of their important role in bridging technology capabilities with end-user needs. Prior work has demonstrated how the technical complexity and non-deterministic nature of AI/ML can introduce many challenges to the design process. The recognition of AI/ML as a 'new design material' [34] has prompted investigations of difficulties UX practitioners face when working with AI/ML [19], specific properties of AI that makes it a unique and difficult design material [67], and how UX practitioners adapt design practices to cater to AI [71]. Another factor to consider is that AI/ML applications are necessitating new kinds of collaboration between UX practitioners and model developers [26]. In conventional software development practices, designers and developers could work fairly independently where a designer would hand-off their designs for implementation by the developer [44]. But introducing AI/ML in the mix disrupts these established practices. In many cases, AI/ML model development precedes 'design work' and UX practitioners might not be involved in the early stages of AI/ML development. While some prior work has reported more positive examples of designers collaborating with data scientists [60, 69], other studies have touched upon challenges to resolve [22, 26]. Taking stock of the literature, we conducted an interview study with 14 UX designers and researchers. A significant difference in our study design is that we use Microsoft's Guidelines for Human-AI Interaction (HAX) [7] as an interview probe. We believe this approach prompted participants to reflect and enabled us to collect rich data and uncover new insights. We also provided participants the option of discussing popular, commercial applications of AI/ML as an example of designing for AI. This option allowed participants to circumvent any restrictions in talking about proprietary information but still surface issues and situate them in specific examples. Another objective of the study was to explicitly inquire about needs and the kind of tools they would like to have. In the interviews and in the later stages of analysis, collaborations with ML practitioners emerged as an important aspect that warranted attention. Thus, in this paper, we describe how UX practitioners' work intersects with ML practitioners', and the collaborative and organizational challenges they face. UX practitioners highlighted how many of their needs for designing with AI/ML such as comprehensible model documentation, transparency of model development processes, and technical support to gain a contextual understanding of the model and leverage it in design activities, tend to be overlooked. Though model comprehension and prototyping with a working AI/ML component were the key issues brought up, U",
    "chunk_order_index": 0,
    "full_doc_id": "doc-d351dc2644fdb606c314890f0871e83f"
  },
  "chunk-75d11a4c934736b7a4a336fb567a067d": {
    "tokens": 1200,
    "content": "attention. Thus, in this paper, we describe how UX practitioners' work intersects with ML practitioners', and the collaborative and organizational challenges they face. UX practitioners highlighted how many of their needs for designing with AI/ML such as comprehensible model documentation, transparency of model development processes, and technical support to gain a contextual understanding of the model and leverage it in design activities, tend to be overlooked. Though model comprehension and prototyping with a working AI/ML component were the key issues brought up, UXP also envisioned playing a more active role in the AI/ML development process. They discussed related tensions of when a UXP is introduced in the overall process, adopting a model-first approach to building AI/ML based applications, and reconciling model-centric metrics of performance with user-centered outcomes. UX practitioners also discussed needs for a 'model sandbox' to support capabilities such as handson interaction with the model, using explainable AI techniques, understanding the underlying data the model was built on, prototyping with real model outputs, and testing different use cases. Based on the data, we use **'groupware systems'** as an analytical lens to derive design implications for tools and features that can support collaborations between UX and ML practitioners as well improve the state of UX practice for AI/ML applications (Section 5.2). While prior work has largely used the theoretical concept of boundary objects to both recognize existing artifacts and create new artifacts, our findings suggest new directions for designing collaborative tools. In summary, our work makes three important contributions. There has been a body of work focusing on everyday practices, challenges, and needs of machine learning practitioners and data scientists. These studies have covered data documentation challenges [12, 32], how organizational factors impact responsible AI development [43, 56], communication challenges with respect to model capabilities and quality [6, 53], and tools to support their work practices [10, 33, 57]. Our work begins to unpack similar challenges faced by a different practitioner group - UX practitioners. We complement these prior studies by reporting on the perspectives of UX practitioners who tend to be non-experts in AI/ML but instrumental in ensuring positive user experiences of AI/ML applications. Second, we extend prior work that has studied how UX practitioners work with AI/ML by uncovering specific collaborative challenges and organizational factors that influence these challenges. While the idea that collaborations between UX and AI/ML practitioners is beneficial is implicit in prior work, we unpack where current practices fall short and how collaborations between UX and ML could be better supported to be mutually beneficial. Third, contrary to prior literature which has relied on 'boundary objects' to derive design implications, our data points to the need for groupware systems to support collaborations between UX and ML practitioners and improve the state of UX practice for AI/ML applications. ## 2 Related Work Studies investigating UX practice in software organizations and collaboration between UX practitioners and developers have been prevalent [13, 22, 24, 44, 50]. The practice of UX designers working with ML engineers or data scientists is a relatively recent shift [26]. In traditional software development, a designer could 'hand-off' designs and specifications to a developer for implementation. But developing AI/ML applications might require tighter coupling between UX and ML practitioners to tackle AI's capability uncertainty and output complexity [67], translation of user needs to AI/ML capabilities [26], and the dynamic and evolving nature of AI due to user interaction and feedback loops post deployment [26, 60, 67]. In this work, we investigate the challenges and needs of UX practitioners working on AI/ML applications in a collaborative, organizational setting. We will discuss prior work that focuses on 1) challenges UX practitioners face when designing for AI/ML and 2) collaboration between UX practitioners and data scientists or ML engineers. ## 2.1 Challenges Ux Practitioners Face When Working With Ai/Ml AI/ML is considered a relatively new design material for UX practitioners to work with [19, 34] and its implications for design practice continue to be investigated. UX designers face challenges in understanding what machine learning is and what its capabilities are [19, 67]. AI and ML's technical complexity poses challenges for designers throughout the design process. Ideation and envisioning uses of AI/ML that did not exist before is difficult without getting a sense of its capabilities and limitations [19, 65, 67]. Dove et al. [19] point out how it might be hard for UX designers to reconcile human and statistical forms of intelligence, especially with regards to understanding what kinds of errors it might make and explaining why it was behaving the way it did. Rapid, iterative prototyping also poses challenges because an AI/ML model is dependent on data and learns over time [19, 67]. As Yang et al. [67] point out, there are more design challenges than design facilitators for human-AI interaction design. Yang et al. [67] attribute AI's source of design difficulty to its capability uncertainty and output complexity. Capability uncertainty refers to the non-deterministic, unknown nature of how AI/ML can behave. It can exist throughout the AI lifecycle because of (un)availability of training data, how the model is trained, possible biases in the dataset, and further learning post deployment from user data. Output complexity refers to how different AI systems can produce outputs ranging from simple to complex. For example, route recommenders or conversational assistants can produce outputs that have infinite possibilities and combinations and hence, cannot be simulated [67]. In response to addressing the unique challenges that AI/ML pose to the design process and to UX practitioners, researchers have developed design patterns and guidelines for human-AI interactions [4, 7], techniques to incorporate model outputs and simulate its behavior in prototypes [61, 65], tools to explore and design for AI failures [36, 46], adaptations to classic UX activities such as sketch",
    "chunk_order_index": 1,
    "full_doc_id": "doc-d351dc2644fdb606c314890f0871e83f"
  },
  "chunk-0280e8bd5202c7a7492e7b5078415125": {
    "tokens": 1200,
    "content": "ers or conversational assistants can produce outputs that have infinite possibilities and combinations and hence, cannot be simulated [67]. In response to addressing the unique challenges that AI/ML pose to the design process and to UX practitioners, researchers have developed design patterns and guidelines for human-AI interactions [4, 7], techniques to incorporate model outputs and simulate its behavior in prototypes [61, 65], tools to explore and design for AI failures [36, 46], adaptations to classic UX activities such as sketching to account for language intelligence [65], and workflows to enable co-creation of AI's form and function along with AI practitioners [62]. Another line of work has investigated how human-centered approaches in AI/ML research such as Interactive Machine Learning (iML) and Explainable AI (XAI) can help address the aforementioned challenges of dealing with ML as a design material for UX practitioners. Feng and McDonald [23] found that UX practitioners' needs and goals were better matched with interactive machine teaching (IMT) paradigm and proposed \"research-informed machine teaching\" (RIMT) to account for how user research can be used as an input in the process of teaching the model. Liao et al. [41] offer design guidelines for how XAI techniques can be used to deliver 'designerly understanding' [17] and transparency of the AI/ML model for the UX practitioner, especially when ideating with pre-trained models. Prior work has also studied different aspects of how UX practitioners tackle these challenges in practice [63, 66, 69–71]. For example, guidelines for AI design helped UX practitioners in getting stakeholder buy-in, team alignment and collaboration, educating themselves about AI, and developing internal resources [70]. However, they still needed support in ideation, learning how to frame problems, identifying the right AI problem to solve for, and adapting to the specific domain and context in which AI is applied [70]. UX practitioners also take on additional, invisible labor to reinforce a 'responsible AI' lens [63]. When working on large language models, they had to sensitize their team to potential harms of the models and figure out responsible prototyping and evaluation practices to mitigate these potential harms for the end-user [63]. Focusing on designers who work on enterprise AI/ML, Zdanowska and Taylor [71] found that processes and practices for designing AI/ML were still a work-in-progress and UX practitioners had to adapt existing HCI/design methods to account for AI. Yildirim et al.[69] also studied a similar context of how experienced designers engage with AI when designing enterprise applications. They found that designers were able to successfully identify when and how AI could create value for users but they had to be brought in to innovate at the system level rather than at the UI level in order to create impact. Close collaboration with data scientists was key for designers to engage with AI as a design material [69]. These prior study designs aim to investigate aspects of UX designers' everyday work practices. However, UX designers and researchers are not at liberty to openly and comprehensively discuss proprietary AI/ML products and associated challenges. Consequently, the data gathered is not grounded in specific examples or instances. To address such limitations and better ground the discussion, we decided to use alternate examples of AI/ML systems in our interview protocol, and additionally, the HAX design guidelines [7] as an interview probe. Our goal was to separate aspects of their work that they cannot talk about from aspects that they could still discuss by situating it in other specific examples or concrete applications of AI/ML. We believe this helped participants share insights more openly as it evoked ideas, details, and needs not identified in prior literature. ## 2.2 Collaboration Between Ux Practitioners And Data Scientists Leveraging AI/ML capabilities in different kinds of products and services have necessitated partnerships between data scientists and designers [26]. Such interdisciplinary partnerships face difficulties in having a common language for communication [26, 69] and achieving a mutual understanding of what each discipline brings to the table [26, 38]. Such classic challenges for interdisciplinary collaboration can exacerbate the problems UX practitioners face when designing for AI/ML (2.1). For example, when embedding UX researchers and designers into a machine learning research Analyzing Collaborative Challenges and Needs of UX Practitioners when Designing with AI/ML 447:5 group to guide human-centered product innovation, Kayacik et al. [38] noted that UX practitioners misunderstanding of ML model capabilities was a significant challenge. As part of a broader study about collaboration practices of UX practitioners, Feng et al. [22] classified challenges of collaborating with ML practitioners as either knowledge challenges or process challenges. UX practitioners also felt that collaborating with ML practitioners took more effort on the latter's part to bridge knowledge gaps and that ML practitioners considered UX as a service and not as a partner [22]. Other studies investigating collaborative practices between UX designers and Data scientists have reported more positive findings [66, 69, 71]. In Yang et al.'s [66] investigation of how experienced designers worked with ML, they found that these designers understood ML at a very high level and used abstractions along with examples to communicate their understanding. Experienced designers also recommended embracing a data-centric culture by utilizing quantitative methods, telemetry data, visualization, and close collaborations with data scientists. Yang et al.'s [66] study also showed that designer-data scientist collaboration could be key as designers who did not have easy access to data scientists at work explored fewer ideas and relied on established designs of ML. In a study of UX practitioners working on enterprise ML systems, Zdanowska and Taylor [71] found that UX practitioners benefited from getting technical AI/ML details early on in the design process and had the skills to collaborate effectively with their technical colleagues, but were limited by organizational structures. Given that the practices and processes for designing with AI/",
    "chunk_order_index": 2,
    "full_doc_id": "doc-d351dc2644fdb606c314890f0871e83f"
  },
  "chunk-e017bfe8addcd1b0cbaad048293f3c6e": {
    "tokens": 1200,
    "content": "designer-data scientist collaboration could be key as designers who did not have easy access to data scientists at work explored fewer ideas and relied on established designs of ML. In a study of UX practitioners working on enterprise ML systems, Zdanowska and Taylor [71] found that UX practitioners benefited from getting technical AI/ML details early on in the design process and had the skills to collaborate effectively with their technical colleagues, but were limited by organizational structures. Given that the practices and processes for designing with AI/ML were still in a state of flux, UX practitioners and data scientists tried to work as closely as possible and were equally involved in making decisions about the system design [71]. In a different study of experienced designers working on enterprise AI, it was found that designers closely collaborated with data scientists and AI practitioners to gain an understanding of how the AI system would work, what kind of training data was required, and data flows within the system [69]. They had a mutually beneficial collaboration as data scientists helped designers check for feasibility of their ideas while designers helped data scientists understand end-user perspectives [69]. Across these prior studies [66, 69, 71], it is implicit that close collaboration with data scientists could be instrumental in alleviating the challenges of designing with AI/ML. Our work begins to unpack what is necessary to have better collaborations. Also, participants studied in prior research either frequently worked with AI [69], had many years of related experience [66], or contributed to the development of AI/ML end-to-end [71]. But UX practitioners are tasked with the responsibility of human-centered design of AI/ML experiences across widely differing contexts. They might be novices with respect to designing for AI/ML. Some work with pre-trained models and others work in organizations that develop AI/ML models in-house. Even in the latter case, some are involved end-to-end in the AI/ML development process while others might come in much later, possibly only after the model has already been developed. UX practitioners also work on AI/ML models for different domains and different modalities across a range of consumer and enterprise applications. How might collaboration with AI/ML practitioners and the challenges UX practitioners face vary across these contexts? We do not aim to address all these organizational factors in this work, but rather present findings that take into account some of these factors and relate them to the challenges UX practitioners face. 2.2.1 When and where do UX practitioners fit in the AI/ML lifecycle? AI/ML development processes tend to be complex, longer, and not as well defined compared to traditional software development processes [7, 48]. Unlike traditional software development where a designer hands off designs to be implemented by the developer, it is not uncommon for the AI/ML model to be developed first and have a designer come in later to integrate or design a product around it [22]. Yang et al. [66] noted how development times ML development times were usually longer and generally included 3 stages: 1) designers and data scientists identify a design goal that uses ML capabilities to meet user needs, 2) data scientists develop the ML system and designers work on the UX and interaction design to realize this goal, 3) Iterative testing and improvements after deployment. Most participants, however, reported that they got involved only in the second stage as UX designers in Yang et al.'s study [66]. Windl et al. [64] further identified four different pragmatic approaches for how designers engaged in the AI development process: a-priori, post-hoc, model-centric, and competence-centric. In an a-priori approach, designers dealt with the AI model as an 'a-priori' artifact, whereas in a post-hoc approach designers iterated and developed an interface and handed it off to the data scientists along with specifications of what the underlying model should do and accept as inputs. In both these approaches, there was a separation between the design and model development teams. In contrast, a model-centric approach had designers being involved in every step of the model development process and closely working with AI practitioners. A competence-centric approach leveraged the diverse skill set of designers and data scientists to engage in a truly divergent design process. Though efforts were not as synchronized as in the model-centric approach, it was well-suited for exploratory projects where the characteristics of AI were yet to be defined. Depending on the approach followed, designers were involved in different stages of the AI development process and hence, had varying levels of interaction with the data and models, and collaboration with the AI experts [64]. Such a framework is useful to identify the different organizational structures in which UX practitioners are embedded to work on AI/ML and analyze how their needs might vary across these four approaches. 2.2.2 Artifacts to support collaboration. Understanding how different boundary objects [59] can support collaboration between designers and data scientists has also been studied in the literature [9, 14, 66, 69]. Yang et al. [66] explain how designers understood ML through high-level abstractions and exemplars, and used the same to communicate their design ideas, what ML capabilities would be possible, and how it would be useful for end-users. Hence, these abstractions served as boundary objects, allowing designers to communicate effectively with data scientists. In Yildirim et al. 's study of enterprise AI development [69], different artifacts such as whiteboard sketches, visualizations, annotated wireframes and service blueprints functioned as boundary objects that helped data scientists and designers achieve a shared understanding. Ayobi et al. [9] explored how ML explanations can serve as boundary objects in a co-design workshop that included AI and HCI researchers, industry practitioners, and diabetic patients. But explanations had to be made 'plastic' enough to be useful and accessible for non-experts of ML. This involved abstractions and relating explanations to real life experiences and contexts [9]. Cai et al. [14]",
    "chunk_order_index": 3,
    "full_doc_id": "doc-d351dc2644fdb606c314890f0871e83f"
  },
  "chunk-a7a067462b73d6eb851fba1341f6fab2": {
    "tokens": 1200,
    "content": "blueprints functioned as boundary objects that helped data scientists and designers achieve a shared understanding. Ayobi et al. [9] explored how ML explanations can serve as boundary objects in a co-design workshop that included AI and HCI researchers, industry practitioners, and diabetic patients. But explanations had to be made 'plastic' enough to be useful and accessible for non-experts of ML. This involved abstractions and relating explanations to real life experiences and contexts [9]. Cai et al. [14] described how the process of creating onboarding documents for a neural network model that detected prostate cancer, enhanced the team's understanding of pathologists' expectations, needs, and evaluation criteria. This process helped different stakeholders, including the pathologists, arrive at a design of the model that would be applicable and useful in practice, with the onboarding documents serving as boundary objects [14]. The notion of boundary objects is based on standardized methods of collaboration and cooperation [59]. But it is also apparent that collaborations between AI/ML practitioners and designers are non-routine, emerging forms of collaboration which might have boundary-negotiating artifacts in play instead [40]. This line of research is relatively understudied with the exception of Subramonyam et al.'s [60] work, though the artifacts studied in their investigation break rather than establish boundaries. In Subramonyam et al. 's [60] work, they define 'leaky abstractions' as 'ad-hoc representations exposing low-level design and implementation details', and describe how such representations get shared by both designers and AI practitioners to bridge knowledge gaps. These artifacts help in communication and knowledge sharing across boundaries in collaborative design of AI systems. Thus, leaky abstractions help break through the supposed 'boundary' between different communities of practice and oppose the separation of concerns principle followed in more traditional software development [60]. One objective of our study is to also understand what other kinds of collaboration artifacts would be useful, according to UX practitioners. Do UX practitioners perceive needs for artifacts that would influence UX practice, to support cooperative work, articulation work or close collaborations with ML practitioners? Based on participant description of hypothetical artifacts that they would like to have, we aimed to better understand their goals. ## 3 Methods We conducted an interview study with 14 UX practitioners on their experiences of designing AI/ML applications. Since participants might not be able to discuss the proprietary AI/ML applications, we provided them the option of talking through either recommender systems or smart features in an email system as an example of designing for human-AI interactions. We recruited participants by posting our recruitment survey on LinkedIn, Twitter, and mailing lists, and screened interested participants based on our inclusion criteria. Interviews were conducted virtually using Zoom and lasted for 1 hour. Participants were provided an honorarium of $25 for their time. After transcribing interview data, we did an inductive analysis to identify concepts and themes emerging from our data. Below we provide details about our recruitment methods and participants, interview protocol, and data analysis. ## 3.1 Recruitment And Participants We wanted to interview participants who were either currently working on or had previously worked on AI/ML applications in a UX capacity. We prepared a recruitment survey with questions about amount of formal education, field of study, current job title, years of experience in the UX industry, size and structure of UX team in their organization, AI/ML expertise, if they have worked on products that utilized AI/ML, high-level description of the product they worked on (optional question), and whether they wanted to talk about recommender systems or email systems as an example application of AI/ML. We obtained IRB approval for this study and posted the recruitment survey on LinkedIn and Twitter. We also circulated it using relevant mailing lists and alumni Slack channels of the authors' University. We screened for UX professionals who were currently working on AI/ML or had previous related work experience and invited them for an interview using the contact email provided in the recruitment survey. We scheduled virtual interviews over Zoom for 1 hour and provided an honorarium of $25 to all participants. All interviews were recorded to be transcribed later. Fourteen (14) UX practitioners, who held various titles, participated in our study. Six participants were UX Researchers and five were UX/Product designers. One participant, P11, had a generalist UX role and prior experience as a user researcher. Two other participants held the titles Conversation Designer and UI Tech Lead. In terms of industry experience as a UX practitioner, three participants had 1-3 years of experience, six had 3-5 years of experience, three had 5-10 years of experience, and two had over 10 years of experience. All participants were working on AI/ML related products or features at the time of interviewing. Participant details are also provided below in Table 1. Participants of the study reported working with various stakeholders such as other UX practitioners, data scientists, AI/ML engineers, software developers, and product managers. Based on their work, they needed to collaborate with additional stakeholders as well. For example, participants | Size and Structure | | | | | |-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------|--------------------------|--------------------|----------------------------------------------------------------------| | Participant ID Job Title | Years of UX experience | AI Product Area | | | | of UX team in Organization | | | | | | P1 | UI Tech Lead | 3 - 5 years | Small | Fraud detection | | P2 | UX Designer | >10 years | Dedicated UX | Repetitive task automation | | P3 | Senior Conversation | Chatbots, NLP, Recommend | | | | Designer | 3 - 5 years | Small | and predict intent | | | P4 | UX Researcher | 3 - 5 years | Small | Smart Assistants | | P5 | Product Designer | 3 - 5 years | Small | NLP-based recommendation, summarization, classification",
    "chunk_order_index": 4,
    "full_doc_id": "doc-d351dc2644fdb606c314890f0871e83f"
  },
  "chunk-48b8fa7f7400a9757bd4d74bf0a5a80f": {
    "tokens": 1200,
    "content": "detection | | P2 | UX Designer | >10 years | Dedicated UX | Repetitive task automation | | P3 | Senior Conversation | Chatbots, NLP, Recommend | | | | Designer | 3 - 5 years | Small | and predict intent | | | P4 | UX Researcher | 3 - 5 years | Small | Smart Assistants | | P5 | Product Designer | 3 - 5 years | Small | NLP-based recommendation, summarization, classification | | P6 | UX researcher | 1 - 3 years | Small | NLP application | | P7 | Senior UX Researcher | >10 years | Dedicated UX | NLP, Classification, BERT | | P8 | UX Designer | 1 - 3 years | Medium-sized | Designing front-end of decision support systems utilizing AI/ML | | P9 | UX Researcher | 3 - 5 years | Small | Generate personalized recommendations | | P10 | UX Researcher | 5 - 10 years | Small | Differentiating musical genre of a song in a file | | P11 | UX Generalist | 3 - 5 years | Small | LLM applications for code | | P12 | Senior UX Designer | 5 - 10 years | Medium-sized | Automating clinical assessments in clinical point-of-care ultrasound | | P13 | UX Product Designer | 5 - 10 years | Small | Predictive Analytics | | P14 | User Researcher | 1 - 3 years | Small | Enterprise products for business predictions | | Table 1. Participant information. The experience of participants pertains to their general experience of working as a UX practitioner and not years of experience working on AI/ML products specifically. Corresponding | | | | | P12 Senior UX Designer 5 - 10 years Medium-sizedAutomating clinical assessments in clinical point-of-care ultrasound P13 UX Product Designer 5 - 10 years Small Predictive Analytics P14 User Researcher 1 - 3 years Small Enterprise products for business predictions Table 1. Participant information. The experience of participants pertains to their general experience of working as a UX practitioner and not years of experience working on AI/ML products specifically. Corresponding survey options for the size and structure of UX teams are: i) The UX team is quite small and we manage all UX-related work across the board (Small), ii) The UX team is medium-sized (Medium-sized), and iii) Almost every team has a dedicated UX professional (Dedicated UX). All participants were working on AI/ML products at the time of interviewing. who worked on enterprise software had to work with clients and customers. P12, who worked on a clinical application, also worked with subject matter experts. For ease of reading, we use the acronym UXP to refer to UX practitioners in our study, though some are designers and some are researchers. Similarly, we use the acronym MLP (machine learning practitioners) to refer to the model developers, although some participants called themselves data scientists, while others identified as AI or ML engineers. ## 3.2 Interview Protocol We used Microsoft's Guidelines for Human-AI Interaction (HAX Guidelines) [7] as an interview probe to elicit concrete responses and to get insights on how participants applied the guidelines to different design problems. Since participants may not be able to share proprietary details of the applications they are working on, we provided them the option of discussing and grounding challenges of designing AI/ML in examples of everyday use of popular AI/ML applications such as recommendation systems or smart features in email (classifying spam, smart compose). 1 We provided the HAX guidelines for the participant to read through as soon as they agreed to participate in the interview study. During the interview session, we showed specific HAX guidelines and associated examples for recommender systems or email systems based on participant's choice. The first half of the protocol included basic, preliminary questions about the participant's industry experience as a UX practitioner, what stages were they involved in while working on AI/ML products, whether the AI/ML models were developed within their organization, reactions to HAX guidelines and examples, if they could recall an instance when an AI/ML application (recommender systems/smart features in email) did not work as per their expectations, and how they would apply the HAX guidelines. If they could, participants were also encouraged to discuss instances from their work when their own design had unexpected outcomes for the end-user. Based on participants' examples, we elicited what was challenging about working with AI/ML and strategies they use to overcome them. The second half of the protocol focused specifically on collaborative practices of UX practitioners. By probing how they might use HAX guidelines for collaboration, we covered how UXP currently collaborate with MLP, tensions, if any, in collaborating with MLP, needs for working with AI/ML and collaborating with MLP, and if there was particular information, resources or artifacts that would be useful to facilitate collaborations. Participants discussed examples and practices from their work experiences to lend support to the challenges and needs they surfaced. We obtained rich, qualitative data from participants based on their perspective as a UX practitioner. Participants in the study provided data more broadly about how UX as a discipline can tackle designing for AI/ML as well as specific aspects of working with AI/ML as part of their organizations. For this work, we report results that relate to UXP working on AI/ML products in a collaborative, organizational setting with stakeholders such as ML practitioners and/or data scientists. ## 3.3 Data Analysis The first author transcribed the interviews using Zoom's audio transcription services. Transcripts were manually validated, correcting errors in the automated transcription. Our overall data analysis was guided by the procedure for developing grounded theory [16]. The first author conducted an initial round of open coding, concentrating on practices, strategies, views, needs, and organizational factors mentioned",
    "chunk_order_index": 5,
    "full_doc_id": "doc-d351dc2644fdb606c314890f0871e83f"
  },
  "chunk-1d0cdeb289add579f813a43c571d7bbe": {
    "tokens": 1200,
    "content": "UXP working on AI/ML products in a collaborative, organizational setting with stakeholders such as ML practitioners and/or data scientists. ## 3.3 Data Analysis The first author transcribed the interviews using Zoom's audio transcription services. Transcripts were manually validated, correcting errors in the automated transcription. Our overall data analysis was guided by the procedure for developing grounded theory [16]. The first author conducted an initial round of open coding, concentrating on practices, strategies, views, needs, and organizational factors mentioned by participants. The first author then started grouping related codes into subcategories and categories. In the second round, we moved to axial coding, recognizing relationships between coding subcategories. For example, we were attuned to what kind of challenges UXP described in engaging with AI/ML or collaborating with MLP, different strategies UXP employed to overcome challenges, whether these strategies were effective, and solutions proposed by UXP to address said challenges. We also compared and contrasted different participant accounts to understand how contextual factors such as organizational structure influenced UX practice. Throughout the coding process, the two authors discussed codes, rationale for including a code in a coding category, memos, and iteratively refined the grouping of codes. Finally, we did selective coding to identify the core phenomenon of interest - how UX practitioners' collaboration with MLP influences design practice of AI/ML. We used it as our organizing concept and analyzed how other coding categories relate to it in order to explain the core concept in detail. ## 4 Findings Participants discussed various challenges, tensions, and needs with regards to collaborating with MLP. Five key themes emerged in our analysis which we discuss in detail below. ## 4.1 Communication Gaps Between Uxp And Mlp Many participants mentioned that there was a big communication gap between UXP and MLP. The language and vocabulary used by MLP to talk about the AI/ML model and different techniques used to develop it were not comprehensible for UXP. \"There is a huge gulf between the words that the data scientists use and the words that regular people use. How do we talk about these things like I am in my domain, you are in your domain, right? So we need to meet in the middle. I think there are a lot of challenges around that.\" - P3 These differences and challenges were more apparent in collaborative settings, such as team meetings. P13 felt that data scientists were generally oblivious to how much UXP did not know about developing AI/ML models as they talked about 'all the math stuff' in meetings. P3 also had a similar experience. Despite taking introductory courses to AI, P3 could not follow their conversations as it was highly technical. Getting into the specifics of AI/ML techniques or algorithms without abstracting the details made it difficult and intimidating for UXP to engage in these discussions. There might be a pressure to know these concepts and sometimes UXP feared revealing incompetence by asking what might be considered basic or dumb questions. \"People that don't know anything will not talk in meetings, and they'll just agree, because it is scary, and we don't really know if it's accurate or not.\" - P13 Such communication gaps can inhibit UXP from contributing their expertise and be a barrier for effective cross-functional collaboration between UXP and MLP. Other participants reported working in smaller teams with ad-hoc collaboration styles (P5) and with MLP who were receptive and willing to answer 'dumb questions' (P5, P12) or they depended on their technical background to follow what was happening (P6, P8). 4.1.1 Improving communication and documentation practices. In order to address communication challenges, UXP wanted i) a routine practice of Q&A time with MLP, ii) internal training to learn basics of AI/ML, and iii) good documentation in place to support communication. UXP said they would like dedicated time with MLP, as a routine or formal practice, to talk about the model and ask questions. \"If I don't understand something, I need to go and resolve it, and I often do that with the PM2 and sometimes the PMs do have to loop in the data scientists. So if there was a formal mechanism to maybe make sure that questions are resolved with data scientists before we launch something, that might be helpful.\" - P14 P5 also echoed this need to ask questions about how the model might benefit users, how good the model is, what kind of errors the model might make, the likelihood of the possible errors, and when it would be ready for user testing. Some (P11, P14) also expressed the need for internal training, learning resources, and onboarding materials tailored for UX practitioners who are new to AI/ML so that they can learn basic concepts and terminology. When an ML engineer who was an external consultant provided helpful documentation about the model to P13, he realized the utility of having such things in place for collaboration. \"If I built it inside, I wouldn't make a powerpoint, or this crazy presentation, because it's like we work together right? But maybe again too - it's like setting standards on how to communicate would be helpful right? If there was a document template that I could give to a developer or data scientist, you know? That would be great.\" - P13 Analyzing Collaborative Challenges and Needs of UX Practitioners when Designing with AI/ML 447:11 P8 also raised the need for having documentation in place that can align the larger team and provide information necessary for designing with the AI/ML model. \"To bring everyone to the same page, we would be having some sort of documentation in place. Suppose, if you are bringing in an AI capability, maybe you can start with an introduction, what it is solving, how it is solved. . . Things that are important to know for anyone who is dealing with an ML algorithm and wants to incorporate it in their design",
    "chunk_order_index": 6,
    "full_doc_id": "doc-d351dc2644fdb606c314890f0871e83f"
  },
  "chunk-9308289a28c88d57f8320a611094e02c": {
    "tokens": 1200,
    "content": "the need for having documentation in place that can align the larger team and provide information necessary for designing with the AI/ML model. \"To bring everyone to the same page, we would be having some sort of documentation in place. Suppose, if you are bringing in an AI capability, maybe you can start with an introduction, what it is solving, how it is solved. . . Things that are important to know for anyone who is dealing with an ML algorithm and wants to incorporate it in their design.\" - P8 Though participants hinted at 'document templates' and 'things to know as a designer', it can be hard for them to exactly articulate and codify their model information needs. They are still figuring out, retrospectively, what is useful to know and what they need to know. Rare encounters with the model directly or conversations with MLP can reveal information that UXP did not know that they needed to know beforehand. Although recent work unpacks designerly understanding of AI [41], model interpretability needs of UX practitioners is a relatively understudied area. Model documentation frameworks [25, 45] largely cater to model developers or experts of AI/ML and need to be translated for other stakeholders who are not experts in AI/ML. UX practitioners' ask for comprehensible model documentation is one part of the solution as they voiced other needs to fill knowledge gaps which we discuss below. ## 4.2 Lack Of Visibility Into The Model Building Process Our participants did not have any insight or visibility into how MLP trained and developed AI/ML models. They wanted to understand the different processes and stages of model development and its outcomes on the model. For UXP, getting these insights can increase general AI/ML literacy and contribute to model understanding. 4.2.1 Understanding the model training phase. P12 spoke about wanting to know if the AI gets trained once or continuously. As a designer, P12 felt understanding the context around how a model gets trained and learns patterns was important to design a good system. P12 and P14 wanted to have awareness on how training data is collected and the mechanisms used to train the model. This can help in analyzing how user feedback in research studies relates back to what data was used. For example, P14 wanted to know whether synthetic data was used in the training process and evaluate whether it affected how end-users perceive model outputs. \"I would like to understand how the data was gathered to train the model, because we often don't have access to it. Data scientists get very crafty with how they're collecting representative data. There are lots of different mechanisms for feeding into the training. As you think about testing it with potential users, they're going to have different feedback right on its outputs, and that could potentially, I don't know, be dependent on where the data came from and how it was trained. If you're using the synthetic data generator, it's probably going to do . . . I mean it probably has its own limitations relative to a different data source.\" - P14 P14 views awareness around training processes and data as a dependency to contextualize findings from user research but it is not something that they typically have access to. 4.2.2 Making model development visible. P3 observed how stakeholders, sometimes, unrealistically expected MLP and DS to magically whip out models given either a problem statement or a dataset because like UXP, they did not have a good enough understanding of the model-building process. P14 notes how they did not realize the complexities of an ML practitioner's work until they worked on a separate project that involved interviewing MLP and asserted that it would be helpful to understand these complexities as part of working in their regular teams. \"I didn't realize a lot of the complexities that they worked with. How many models that they might test before one gets deployed within a product. A lot of this would actually be helpful to know and understand. I personally would benefit from a better understanding of different model types, right? And why a certain model gets picked, or is deployed over others.\" - P8 P5 wanted to know timelines of model development and readiness so that they could do design iterations and conduct user research studies accordingly. \"The model was not really ready anyway. I started seeing way more errors than I expected to see and super low confidence scores. And the model hadn't really been calibrated yet. So I ended up changing my user study that I was planning and shaped the questions to be more exploratory. I think they [MLP] were aware of the problems already. So it was just me realizing the extent of the problem.\" - P8 Making MLP workflows visible can help set expectations, inform UX practitioners' understanding, and coordinate UX tasks. P3 also speculated about tools that would satisfy this need. \"Thinking about where the model is built. A lot of times it is just built in like whatever program the data scientist is using. And UX-ers are not even gonna know what that is. What would a UI look like that made a model visible, as it is being built? You know where they [UXP] can say 'I see where you are right now, what are you thinking here?' I don't know if that would be doable. . . That could help.\" - P3 P3 wondered if a tool or application can be built internally so that UXP could access it to get more visibility into the model building process. Such tools can potentially facilitate collaborations with MLP while also enabling the UXP to participate early in AI/ML development. In summary, UXP highlighted the need to have visibility into and awareness of how MLP work, including their objectives, rationale, processes, and timelines. UXP believed it could help with collaborations, improve their basic understanding of AI/ML, and directly inform UX practice. ## 4.3 Synergy Between Ux And Ml Practice UXP discussed issues with reconciling user-centric outcomes with model-centric metrics and",
    "chunk_order_index": 7,
    "full_doc_id": "doc-d351dc2644fdb606c314890f0871e83f"
  },
  "chunk-dcc2c4dea3e8b98c7d4253cee1a65d2f": {
    "tokens": 1200,
    "content": "LP while also enabling the UXP to participate early in AI/ML development. In summary, UXP highlighted the need to have visibility into and awareness of how MLP work, including their objectives, rationale, processes, and timelines. UXP believed it could help with collaborations, improve their basic understanding of AI/ML, and directly inform UX practice. ## 4.3 Synergy Between Ux And Ml Practice UXP discussed issues with reconciling user-centric outcomes with model-centric metrics and relatedly, having MLP understand end-user perspectives. We discuss both under the broad category of aiming for synergy between UX and ML practice when developing AI/ML applications. 4.3.1 Reconciling user-centric outcomes with model-centric metrics. One challenge of working with models that have been developed a priori is that they may or may not fit user needs. P9 worked as part of a product team that had a clear and distinct separation from the research team which developed AI/ML models. P9 explained how the two teams have varying goals and motivations for model evaluation, which was challenging for collaboration and hard to reconcile. \"From the product side, if we're testing a model, even if the results are like our users don't find this helpful at all, maybe they don't see themselves using it as part of the product - It's fine because we're just trying to build whatever is most useful, and if this doesn't work for them, then we shouldn't put it on the product. But I guess, for the research side, it is more like validating it - Is this much better than the previous version, but not trying to answer if we want to add this to the product, what is the best place? Where would this fit into the existing workflow... If we look at it by itself, it works better. So I feel like the considerations are just a little bit different.\" - P9 P5, who worked in a similar team structure, always made it a point to ask, *\"Which ones are really* cool for science and academia and which parts are actually going to be useful to users?\". Even in other Analyzing Collaborative Challenges and Needs of UX Practitioners when Designing with AI/ML 447:13 organizations where a dedicated MLP is assigned to a product team, this issue crops up between UXP and MLP. \"This is actually more of a personal opinion on how ML & data scientists work. They are looking at the model performance. They are not looking at the qualitative side of the impact. And so there is a big gulf there. Just because your model is performing correctly doesn't mean that users are, you know, actually enjoying the thing that you are showing them, right? It is looking at outcomes versus outputs.\" - P3 P3, again, points to the divergence in how UXP and MLP consider model performance. While looking at both model-centric metrics and user-centric outcomes are important, the viewpoints of UXP calls into question how user-centric outcomes are assessed and codified in ML practice, and more broadly in the organization as well. A lack of shared goals for model evaluation is another source of tension in collaborations between UXP and MLP. 4.3.2 Having MLP understand end-user perspectives. UX practitioners wanted MLP to be involved in user research and understand user perspectives and behaviors around the model. This way, UXP hoped to influence more human-centered approaches to model development. For example, P13 wanted to involve MLP early on in user research efforts in the hope that more models could be developed based on an understanding of user needs and use cases rather than developing models first and then figuring out how it would be used. \"Yeah, I think it would be for them to understand who's using it right, and really getting all these folks engaged more so, into actual use cases. So then we can start building and thinking towards that versus like a step process like, \"Hey, we're gonna make this. And then you're gonna tell us how to use it\" versus \"Hey? Let's learn what we need to do, what the problem is, and then build for that\". So I think it's getting them involved in user research at the beginning, understanding what data we have.\" - P13 P3 recalled how few ML engineers sought their UX expertise for feature engineering in a prior job, but notes that it was not an organization-wide practice. \"In previous jobs, sometimes the ML engineers would come to me to ask questions, to build models. But that was not structural. It was because they knew that I knew the product well and knew what customers were doing. So they saw me as a subject matter expert almost. So I helped them with feature engineering.\" - P3 Other participants also echoed how important it was for ML practitioners to challenge their assumptions and understand user perceptions of the model. \"For data scientists to understand what our users are saying. There's a very broad spectrum of user understanding when it comes to the model performance and calibrating users to that right? Beyond research report-outs. . . sometimes, and they [users] say. 'Oh. 99%, that's awesome, but why is it red? Why is it showing red?' Because that's like an overfitting example. And there are users that understand that perfectly - that 99% is bad. And there are users that think something might be wrong as the model can't be this accurate. And so I also want data scientists to have that awareness of how users think about these things.\" - P14 P9 said that end-users often have questions in research sessions about how the model works, whether it could do other things, and if certain improvements could be made, for which P9 did not have answers. Having ML practitioners or researchers who developed the model participate in research sessions would be helpful in two specific ways. First the MLP could easily field those questions (P9). Additionally, MLP participation would help them understand",
    "chunk_order_index": 8,
    "full_doc_id": "doc-d351dc2644fdb606c314890f0871e83f"
  },
  "chunk-85e40424c11dada5c2d19da119b18ef6": {
    "tokens": 1200,
    "content": "to have that awareness of how users think about these things.\" - P14 P9 said that end-users often have questions in research sessions about how the model works, whether it could do other things, and if certain improvements could be made, for which P9 did not have answers. Having ML practitioners or researchers who developed the model participate in research sessions would be helpful in two specific ways. First the MLP could easily field those questions (P9). Additionally, MLP participation would help them understand the difference between users' mental model of how the model works, users' expectations of how it should work, and how it actually works (P9). P11 recommended showing videos from user research sessions to demonstrate how users interact with the model to challenge assumptions and preconceptions MLP might have. P11 also felt such proactive efforts from UXP can help MLP recognize the value in doing UX research. ## 4.4 Establishing A Process For Collaboration Between Uxp And Mlp Another challenge specified by UXP was that the organizations they worked in had no established process for collaborating with MLP. Ideally, UXP would like to be involved early on but this was not the case. 4.4.1 Bringing in the UXP early. Figuring out the details of when and how to bring in a UXP and have them contribute to the model development process can take significant effort and time (P3). In the interest of staying fast paced, organizations might prioritize shipping models rather than bring in the UXP, address the aforementioned challenges, and figure out a process for how UXP and MLP could work together. \"Having designers work with ML engineers and data scientists. It's easier said than done. And when you look at the traditional structure of all organizations, it is - this is what I do, this is what you do. And to bring someone in knowing when to bring them in, how to bring them in, and you are always up against the battle of 'This is slowing us down!'. A lot of times, what I notice is, they just want to get a model out. Ship it, prove it works. And that is a different incentive, than say, are we getting it right for our customers.\" - P3 P12 pointed out that most technology-based organizations, not just AI-based organizations, are engineering or product driven and it is not uncommon for UXP to come in later. Meanwhile, \"real design work was already done by whoever just happened to be in the conversation earlier\". P12 acknowledged that as a designer he had a very basic understanding of AI systems. He still wanted to have a *\"seat at the table early on\"* so that the voice of UX/Design discipline is included in discussions and decision-making. Echoing this, P3 wanted organizations to figure out a workflow for how to bring designers and researchers early into the AI/ML development process so that they can focus \"on what it means to be impacted by these systems rather than building a model that performs well.\" 4.4.2 Tensions in model-first versus product-first approaches. P13, who worked on B2B applications, was involved from the ideation stage for some projects and he had to work with a developed model for others. This variation was part of how his organization worked but P13 admitted that doing the latter was harder. \"It's just how my internal organization works. It's kind of sporadic where some projects are more fleshed out and - it deals with like the success of it, because if somebody kind of gives you something that's already made, and then they have the user in mind as an afterthought, then it's a little bit harder to like make it work.\" - P13 Some participants voiced the need for developing AI/ML models that are grounded in user needs. Both P9 and P5 worked as part of product teams while research teams developed AI/ML models. While P5 thought it was natural that only some models from the research team make it into the product, P9 thought it would be ideal if the two teams could work more closely to avoid developing models that do not serve user needs and reduce potential cost of rework. \"It is what we're trying to do, like if there's a new research project coming up, we're hoping that it's motivated by some needs or pain points that we have found previously. Instead of doing it the other way around - like building the model, and then find out that it's not as useful as we hoped.\" - P9 Analyzing Collaborative Challenges and Needs of UX Practitioners when Designing with AI/ML 447:15 P13 wondered if they could draw on co-design methods for building AI/ML capabilities together with data scientists, surfacing doubts in the process - \"This is a data thing, it's machine learning. It's very technical and co-design, it seems really squishy, and how do you co-design virtually? Or how do you co-design with people that are very different from you, right? And I think as a UX Designer or researcher, that is probably on us more right? So I think it's just we have to kind of get in there and do it.\" - P13 Other UXP focused on tools and practices that would enable them to do better in their current roles and functions which we discuss next. ## 4.5 Leveraging The Ai/Ml Model In Ux Practice UXP had several ideas about how to address gaps in the current ways of understanding and designing with the AI/ML model, and improve collaborations with MLP. UXP sought direct or indirect support from MLP in service of understanding the model insofar as it enables design activities and prototyping with functional AI/ML. They came up with different ideas for artifacts and solutions that would mediate these collaborations. 4.5.1 Model Comprehension. In terms of model documentation, UXP either did not receive any or the",
    "chunk_order_index": 9,
    "full_doc_id": "doc-d351dc2644fdb606c314890f0871e83f"
  },
  "chunk-e97c11997cd317d0ed4338750b3e5bf8": {
    "tokens": 1200,
    "content": "to address gaps in the current ways of understanding and designing with the AI/ML model, and improve collaborations with MLP. UXP sought direct or indirect support from MLP in service of understanding the model insofar as it enables design activities and prototyping with functional AI/ML. They came up with different ideas for artifacts and solutions that would mediate these collaborations. 4.5.1 Model Comprehension. In terms of model documentation, UXP either did not receive any or the resources provided were highly technical and unhelpful (model architecture diagrams, scientific papers). Few participants (P8, P9, P13) spoke about having some sort of relevant, comprehensible documentation in place to provide useful information about the AI/ML model for a UX practitioner. In scenarios when MLP cannot be a proxy for model understanding (organizational structure, employee attrition), UXP-oriented model documentation can compensate for it. P11 also cautioned that model documentation could only go so far in enabling the UXP to understand the model in context. \"[Some] models are hard to capture in precise documentation. I mean, of course, you can say it has this many billion parameters, and you know the confidence scores or like the prediction percentage - is this accurate, and you could give some metrics, but it's hard to know, like how to make sense of those metrics in context.\" - P11 P11 highlighted the distinction between the traditional metrics and documentation that MLP might maintain for their own use and the potentially low utility of that documentation for UXP use. Participants mentioned wanting to gain a more tangible and contextual understanding of the model in whatever ways possible. P9 said seeing demos of how the model works, what outputs are produced for different inputs would be helpful, and what the model can and cannot do would be useful. Additionally, P9 wanted to understand if the model had any constraints, in terms of working better for certain user groups than others. P3 also advocated for showing what the model could do and using visualizations that are accessible for non-experts of AI/ML as a starting point. P3 also wanted support for explainable AI features and interrogating model outputs, through technical tools or MLP themselves, although they understood that this was not always possible and depended on the model architecture. Moving beyond the idea of static documentation, P11 suggested the idea of a model sandbox which would allow UX practitioners to have hands-on interactions with models and derive insights by testing different data, something that documentation would not support. \"Having a sandbox where everyone in the team can play with the model. There's nothing that replaces that. . .Having a sandbox where the UX professionals could actually interact with the model and test the model and test like. 'Oh, how would it give me suggestions for smart composition if I give this example versus this example versus this example' right? So I think that it's really really important, like having internal tools for people to be able to get a sense of model capabilities hands-on and interact and play with it.\" - P11 P7 suggested similar ideas but called them 'self-service models'. He considered how self-service models can enable understanding of data context of AI/ML models, which in turn can help UXP design congruent research studies. \"We need to improve self-service models for user and user experience researchers. Let the UXR play with the models and understand how the data looks like - the shape of the data - this can help UXR design better research studies. No more black boxes - reveal the underlying assumptions behind the model.\" - P7 4.5.2 Creating and testing prototypes with working AI/ML components. UXP stressed that it was of limited utility and unrealistic to test prototypes that did not have a working AI/ML component. Though some UXP shared positive experiences of collaborating with MLP to create such prototypes, it was not a routine practice and had associated time and resource constraints. P5 wanted to design for real-life messiness of data and see samples of model outputs, but felt they were bothering the MLP to get it. \"Sometimes it's helpful to see, 'really, what is this model spitting out?'. Because it's not always like I have guessed in my head. Sometimes it looks messier in real life than when I'm just filling in placeholders on Figma. If I can get data samples of what might be the outcome of this model, that's helpful. Usually I have to bother the researchers a bunch of times for it.\" - P5 P11, who had similar needs, speculated about connecting prototyping tools to the previously suggested idea of a 'model sandbox' to create effective and functional prototypes for AI/ML. \"What if I could have a way to plug that into my model sandbox, and in my prototype be able to get responses, right? What if I could actually have a mockup of the application, or an interactive prototype that I could actually test with users. I think there needs to be a way of streamlining how we test these technologies, but also it's not realistic to test the UI or mockup if you can't have some of the queries or the content that is supposed to represent the AI functionality - leading to the actual model. What's missing right now is tools where you can build very quick prototypes in order to get feedback rather than waiting for the engineering team to put out a product and going and evaluating that?.\" - P11 P11's goal for tools here is to enable rapid prototyping of AI/ML experiences that can precede software development, but still incorporate AI/ML functionality in it. P13 also suggested the idea of a model sandbox to have hands-on interaction with model and data and to test different use cases. As P13 suggests, such tools could also foster collaboration between UXP and MLP. \"Maybe like a sandbox, right? That we could play with or a model that lets us mess with",
    "chunk_order_index": 10,
    "full_doc_id": "doc-d351dc2644fdb606c314890f0871e83f"
  },
  "chunk-1ab9e500c28772075844c7808c40cd36": {
    "tokens": 1200,
    "content": "P11's goal for tools here is to enable rapid prototyping of AI/ML experiences that can precede software development, but still incorporate AI/ML functionality in it. P13 also suggested the idea of a model sandbox to have hands-on interaction with model and data and to test different use cases. As P13 suggests, such tools could also foster collaboration between UXP and MLP. \"Maybe like a sandbox, right? That we could play with or a model that lets us mess with data. So we can test use cases more right? There is collaboration, but a lot of times it's just me handing it off and giving them as many use cases I could think of right. And I know that there's way more, many more. So maybe also to like a way that designers and data scientists could collaborate better.\" - P13 P13 also pointed out that it can be challenging for organizations to find the time and resources to invest in building such tools and infrastructure upfront. \"I think that just depends on the maturity of your organization. Do we even have time to build that - sometimes on that team of five, four people. We don't have time! But I think if we know that this is going to be a long project, and we're going to benefit a lot from Analyzing Collaborative Challenges and Needs of UX Practitioners when Designing with AI/ML 447:17 getting feedback from users that way - putting that infrastructure in place would be great.\" - P13 The challenges highlighted by our participants here align with the findings of Liao et al. [41]. While their work is aimed at uncovering information needs of UXP when ideating with pre-trained models, our work shows that such needs are prevalent even when models are developed in-house. ## 5 Discussion In our data, we see that participants raised a range of issues such as communication gaps with MLP, lack of tools to enhance UX activities for AI/ML, and organizational-level decisions about when a UXP gets involved in the AI/ML development process. These issues arise because of both organizational factors and challenges inherent to interdisciplinary collaborations. Though participants listed challenges for collaborating with MLP, the onus and accountability of addressing them does not fall solely on MLP. In our discussion section, we focus on two topics - examining the role of UX practitioners in human-centered AI/ML development and generating design implications for collaborative tools, inspired by the groupware approach. ## 5.1 Examining The Role Of Ux Practitioners In Human-Centered Ai/Ml Development In our findings, we see that UXP described different intersection points between AI/ML and UX that can be grouped into two categories: MLP in service of UX practice and UXP in service of AI/ML practice. MLP in service of UX practice (bottom arrow): This category describes goals for working with MLP in service of UX practice. UXP sought direct or indirect support from MLP for enabling two important UX activities, especially when working with models that had already been trained. These are model understanding insofar as it enables UXP to design with it and prototyping with real AI/ML functionality. UXP surfaced the need for i) better documentation practices that would make model and training information accessible as well as comprehensible and ii) model sandbox type of tools to directly interact with the model and prototype with it. Although these directions have been explored in prior research [41, 46, 61], our data shows that such tools and frameworks are not yet prevalent in organizational practice. In Subramonyam et al. 's [60] study, we see both designers and AI engineers/researchers sharing different artifacts to represent low-level UX findings and low-level AI/ML implementations, and how sharing of such 'leaky abstractions' helps collaboration. In our findings, UXP expressed a need to start adopting similar practices. That is, they wanted to have more access to the model, data, and model-building process (see Findings 4.2 and 4.5), and they wanted MLP to engage with user research (see Finding 4.3). UXP in service of AI/ML (top arrow): The second category captures how UXP envision influencing AI/ML applications more broadly. Though a few participants were matter-of-fact about incorporating trained models in a product, others felt their role was reduced to giving the AI \"a look and feel\". Despite not having deep technical knowledge about AI/ML, UXP wanted to be involved early on when use cases and model requirements were being established, so that they could represent end-users' needs and perspectives. P3 reported that since they were the subject matter expert in product experience, they were sought by prior MLP colleagues for input on feature engineering. However, to standardize such practices and reduce barriers for UXP to get involved, P3 envisioned internal tools that made a model visible as it was being developed. Evaluation of the model was another area in which most UXP wanted to influence a more human-centered approach as they stressed the need to reconcile evaluations of end-user impact with quantitative performance metrics. ![17_image_0.png](17_image_0.png) Other studies of UX practitioners, specifically in the enterprise context, have noted closer collaborations between UX and ML practitioners, with MLP involving UXP in early stages of model development and for interfacing with end-users, stakeholders, and domain experts [69, 71]. Most of our participants (11 out of 14) worked on consumer-facing products. Without a targeted investigation, it is hard to infer whether such differences in findings are because of differences in organizational structures, team sizes3, or in the context of application development (enterprise vs consumer-facing). Our categorization of these different touchpoints between AI/ML and UX (as depicted in Figure 1 above) allows us to examine to what extent UX practitioners play a role in human-centered",
    "chunk_order_index": 11,
    "full_doc_id": "doc-d351dc2644fdb606c314890f0871e83f"
  },
  "chunk-27c27b9cf9a1126ba0f81eb83f627b5e": {
    "tokens": 1200,
    "content": "69, 71]. Most of our participants (11 out of 14) worked on consumer-facing products. Without a targeted investigation, it is hard to infer whether such differences in findings are because of differences in organizational structures, team sizes3, or in the context of application development (enterprise vs consumer-facing). Our categorization of these different touchpoints between AI/ML and UX (as depicted in Figure 1 above) allows us to examine to what extent UX practitioners play a role in human-centered AI/ML development. Human-centered AI not only involves using methods from HCI to inform the design of AI/ML products, but also involves examining how human-centered considerations are incorporated into the model itself [11]. Decisions made in early stages of establishing model requirements and collecting training data carry implications for 'human-centeredness' and have potential for causing severe downstream effects of bias and unfairness. Developing AI/ML models that are fair, accountable, transparent, and ethical has been an important focus area for the human-centered AI research community [15]. However, we also need to examine what role our counterparts in practice, i.e. UX practitioners play in this broader perspective of 'human-centered AI/ML' and how their involvement could support development of models that are responsible and grounded in user needs. Despite willingness and aspirations to contribute, UXP noted the absence of such practices currently. From our data, we infer that where UX practitioners come into the lifecycle of AI/ML development depends on how the organization is structured and teams are set up, but can subsequently shape their role and contributions. Almost all participants in our study worked in a 'model-first' environment and/or in team structures that were more detached from MLP. Apart from debating product-first versus model-first approaches, they raised the question of who is at the table when decisions are being made about model requirements, capabilities, and what to optimize for. Another factor of influence could be the UX maturity of the organization [5]. UXP in our study noted how effecting change to organizational structures, workflows, and culture is harder to do without push from leadership. They echoed the need for tools and resources instead, that can increase their literacy of AI/ML, make visible invisible aspects of model development, and enable model exploration for a more contextual understanding, in hopes for a more 'concrete change'. To this end, we consider and reflect upon some of the design implications of our work. ## 5.2 Design Implications In this section, we focus on what our findings mean for the CSCW community and implications for design. Participants in our study highlighted various issues that relate to core CSCW issues such as visibility and awareness of work practices, information and knowledge sharing, and supporting cooperative work. Prior work that has studied UX practitioners working on AI/ML and collaborations between UX and ML practitioners have mostly focused on boundary objects as either the theoretical lens or an implication of their work [60, 66, 69]. Prior work has also been geared towards designing artifacts that can support responsible AI practices and serve as 'boundary objects' to facilitate interdisciplinary collaborations. Examples include model cards, datasheets, and data cards [25, 45, 55]. We believe that the concept of boundary objects could be useful and apt in this context, as they are intended to provide a \"means of translation\" [59] and support knowledge sharing across different, overlapping social worlds [59]. However, participants of our study discussed the need for a 'model sandbox' or 'self-service model' (see Findings 4.5), which are clearly not boundary objects. This led us to question whether boundary objects by themselves will be sufficient to meet the needs of UX practitioners and facilitate the kind of collaborations that they envision. Our analysis and reflection points us to another popular approach in CSCW - groupware systems, to generate design implications. We do not suggest replacing artifacts that serve as boundary objects with groupware systems. Rather, we acknowledge that boundary objects pose certain benefits in allowing different groups to work together. But historically, CSCW has produced different theories and concepts to support cooperative work. Solely focusing on one theoretical concept without evaluating the analytical leverage of other concepts can be problematic for how we accumulate understanding about a research topic and limiting in terms of deriving design implications. Consider the case of model cards, which can be a shallow representation of the actual model. In comparison, hands-on interaction with the model can lead to a more constructive understanding. Hence, we need to delineate specific contexts in which boundary objects are useful and does the job, and when we might need other kinds of collaborative artifacts. Data from our participants invoked the idea of groupware systems, which we leverage to characterize artifacts and systems that can support collaborations between UXP and MLP. First, we briefly explain what groupware is for readers who might not be as familiar with it. Then, we will discuss key features of groupware systems, explain our rationale for proposing a groupware-based design, and suggest a few design directions. What is groupware? It might seem odd that, in CSCW, we need to review this concept. But sometimes it is good to revisit foundational concepts when they seem to be so clearly applicable. Groupware can be defined as \"computer-based systems that support groups of people engaged in a common task (or goal) and that provide an interface to a shared environment\" [21]. Groupware has a rich history in the CSCW literature, although they are commonly referred to as just CSCW systems today. While Grudin [29] makes a distinction between groupware that is meant to serve small groups and enterprise systems meant to serve organization-wide goals, Ellis et al. [21] consider a broader scope for groupware. E-mail, video/audio conferencing, chat, electronic calendars, collaborative documents and spreadsheets, and shared whiteboards are examples of groupware systems [21, 58] that are common workplace tools today. Groupware is not",
    "chunk_order_index": 12,
    "full_doc_id": "doc-d351dc2644fdb606c314890f0871e83f"
  },
  "chunk-8d47a99ce6b19561669084196bbc44b8": {
    "tokens": 1200,
    "content": "they are commonly referred to as just CSCW systems today. While Grudin [29] makes a distinction between groupware that is meant to serve small groups and enterprise systems meant to serve organization-wide goals, Ellis et al. [21] consider a broader scope for groupware. E-mail, video/audio conferencing, chat, electronic calendars, collaborative documents and spreadsheets, and shared whiteboards are examples of groupware systems [21, 58] that are common workplace tools today. Groupware is not a monolithic idea. Generally, groupware systems are intended to support group work by enabling communication, collaboration, or coordination; sometimes called the 3Cs [21]. However, systems can focus on one area more than others. For example, applications built around a core feature of exchanging messages focus on communication. Other applications that offer capabilities to share information and operate on this shared information focus on collaboration [21]. When applications incorporate organizational processes and management of workflows, they also support coordination [20, 21]. A component-based approach to groupware, where the application is composed of individual, functional modules providing a selection of capabilities, helps in creating adaptable groupware that can be tailored to a group's collaboration needs [58]. Different groupware technologies can be placed on a spectrum depending on varying levels of support for accomplishing common tasks and/or providing a shared environment [21] 4. Email, while instrumental in supporting communication, might be lower on the spectrum compared to a real-time online document editor. Prior research has studied dynamics of groupware use in organizations [28, 49], groupware related design challenges [21, 29, 51], importance of workspace awareness in groupware [30, 31], as well as application of groupware in supporting collaborative software development [18] and complex scientific data analyses [47]. Why groupware? Each practitioner group typically uses certain applications (that may or may not be groupware systems) to accomplish their tasks [22, 72]. Software developers use IDEs and code repositories. Many data scientists and AI/ML practitioners use computational notebooks, while UX designers largely use tools such as Figma and Sketch. While these applications support each practitioner's work, they can be inadequate in supporting group work, i.e., work that requires these groups of practitioners to come together and collaborate. However, the very definition of groupware mandates access to shared information objects to achieve a common goal. Potential examples of model-related groupware systems exist in the literature although they largely cater to teams of MLP and data scientists [10, 33, 37, 52, 54, 57]. Ziva, a tool created by Park et al. [52] however targets improving the collaboration process between domain experts and data scientists by providing access to shared information. It had interfaces for domain experts to create concepts and provide rationale for data labels in formats that streamlined the model development process for data scientists. Another useful example is AIMEE, a tool created by Piorkowski et al. [54] that enabled editing of the model via a 'rule editor' to account for new requirements and to communicate how a model's decisions have changed after retraining. This tool allowed stakeholders in the team to interactively understand and modify the model's decision boundaries. The authors discussed the utility of such a tool in improving communication and collaboration between data scientists and other team members or clients who might be non-experts of AI/ML, although UX practitioners were not studied as part of the tool evaluation. Based on our findings and principles of groupware design [28, 29], we provide 4 design directions for how a model-related, groupware system can be useful for UX practitioners and support one or more of the 3Cs (communication, collaboration, coordination) with MLP. - Since awareness is an important dimension of collaborative work and groupware systems [30, 31], features providing visibility of the different model development stages and which stage the MLP are currently engaged in are important. If possible, the system can also structure and map these AI/ML lifecycle stages to steps in the design process. For example, if MLP are conducting final evaluations on the model, UXP can be notified so that they can explore model capabilities, leverage it in user research sessions, or start prototyping interactions with model outputs. This stage can be crucial in deciding thresholds and/or mapping outputs of the AI/ML model to relevant information for the user. - Interfaces and interactions in the groupware system should be customized to the needs and role of the practitioner [27]. A component that is useful to a UX practitioner may or may not be useful for a software engineer but could also be useful to a product manager. The categorization we present in Figure 1 can be used to evaluate to what extent a particular groupware component is enabling the UXP in the design process of AI/ML systems. For example, does the groupware component enable UXP in terms of post-hoc model understanding and prototyping? Or does it support UXP involvement in early stages of model development? The design of such components can draw from approaches and techniques in visualization [68], explainable AI [41], and interactive machine learning [23]. - The work involved in maintaining such a groupware system should be balanced with the benefits obtained from it [28]. If more work is required from MLP and data scientists to update model related aspects in the groupware system, then we need to ensure that it offers corresponding benefits and/or automate it. For example, using notebook markdown, basic model information sheet or model cards, could we extract information and represent them in ways that are easier to understand for UX practitioners? How might we design these representations and measure their efficacy? As UXP are not experts in AI/ML specifically, we must ensure that the information provided and ways of presenting it are accessible, comprehensible, and tailored to their needs. But the onus does not fall solely on",
    "chunk_order_index": 13,
    "full_doc_id": "doc-d351dc2644fdb606c314890f0871e83f"
  },
  "chunk-3b8c5dc178386f8cedf345a0af3076fd": {
    "tokens": 1200,
    "content": "ensure that it offers corresponding benefits and/or automate it. For example, using notebook markdown, basic model information sheet or model cards, could we extract information and represent them in ways that are easier to understand for UX practitioners? How might we design these representations and measure their efficacy? As UXP are not experts in AI/ML specifically, we must ensure that the information provided and ways of presenting it are accessible, comprehensible, and tailored to their needs. But the onus does not fall solely on the MLP. - Emphasis on collaborative features should not hinder availability or accessibility of features that support individual work [29], similar to how a collaborative document editor also allows for individual authorship [29]. There are instances when a UXP might work with the AI/ML model independently. But the groupware system must host features to support collaboration and synergy between UX and ML practice when needed (see Findings 4.3). With respect to evaluation, supporting UXP & MLP in analyzing behavioral data, devising user-centered metrics of model performance, evaluating feedback loops, and informing model iterations are a few areas to tackle. When collaborative features of the groupware system are not understood or aligned with practitioners' mental models or if the organization's culture does not incentivize collaborative work, then the groupware might still be used for individual work or not used at all [49]. Thus, model-related groupware systems might be more successful in teams looking to adopt more collaborative practices and/or remove existing barriers for collaboration. Nevertheless, we believe there is promise in using groupware principles to design tools for collaborations between UX and ML practitioners. In future work, we aim to iteratively build and evaluate groupware components with UX and ML practitioners. ## 5.3 Limitations One of the aims of our study was to understand how UX practitioners designed AI/ML applications in a collaborative, organizational setting. Though our analysis generated meaningful insights, they represent only the perspectives of UX practitioners. Case studies of how AI/ML development happens in an organization would be valuable in including the perspectives of different stakeholders, providing a holistic understanding, and surfacing other challenges. Though we attempted to lay out the different organizational contexts in which participants of our study worked there are clearly other organizational structures which are not represented in our data. Another factor that we did not account for in our studies was the complexity of AI/ML systems that UX practitioners were working on. Our study also focused on UX practitioners as if it were a singular group, when in reality, the group can have different job titles, varying skill sets, and come from different disciplinary backgrounds. Hence, the responsibilities they can take on, information needs, and constraints for collaboration could vary. Despite these limitations, we believe our work highlights the organizational nature of challenges UX practitioners face and seek to overcome when designing for AI/ML. ## 6 Conclusion In this work, we present an interview study of UX practitioners working on AI/ML to investigate challenges and opportunities for 1) collaborating with ML practitioners 2) improving the state of UX practice of AI/ML, and 3) influencing AI/ML practice as UX practitioners. Our findings demonstrate how these aspects interrelate and what kind of support UX practitioners seek from ML practitioners and the broader organization. Based on our data, we propose a groupware-based design approach for building model-related tools that can enable UX practitioners in the AI/ML development process. We invite further research focusing on collaborative aspects of AI/ML development and spanning empirical, design, and technical contributions. ## Acknowledgments We thank all the UX practitioners who participated in this study. We also thank our reviewers for providing constructive feedback. This research was supported by a doctoral research grant from the University of Washington's Department of Human Centered Design & Engineering. Meena Devii Muralikumar was additionally supported by the Google Ph.D. Fellowship. ## References [1] [n. d.]. 35 Ways Real People Are Using A.I. Right Now - The New York Times. https://www.nytimes.com/interactive/ 2023/04/14/upshot/up-ai-uses.html. (Accessed on 07/18/2023). [2] [n. d.]. Humans may be more likely to believe disinformation generated by AI | MIT Technology Review. https://www.technologyreview.com/2023/06/28/1075683/humans-may-be-more-likely-to-believedisinformation-generated-by-ai/. (Accessed on 07/18/2023). [3] [n. d.]. The Paradox of Intelligent Assistants: Poor Usability, High Adoption. https://www.nngroup.com/articles/ intelligent-assistants-poor-usability-high-adoption/. (Accessed on 07/18/2023). [4] [n. d.]. People + AI Guidebook - pair.withgoogle.com. https://pair.withgoogle.com/guidebook. [5] [n. d.]. The 6 Levels of UX Maturity - nngroup.com. https://www.nngroup.com/articles/ux-maturity-model/. [6] Jumana Almahmoud, Robert DeLine, and Steven M Drucker. 2021. How Teams Communicate about the Quality of ML Models: A Case Study at an International Technology Company. Proceedings of the ACM on Human-Computer Interaction 5, GROUP (2021), 1–24. [7] Saleema Amershi, Dan Weld, Mihaela Vorvoreanu, Adam Fourney, Besmira Nushi, Penny Collisson, Jina Suh, Shamsi Iqbal, Paul N Bennett, Kori Inkpen, et al. 2019. Guidelines for human-AI interaction. In *Proceedings of the 2019 chi* conference on human factors in computing systems. 1–13",
    "chunk_order_index": 14,
    "full_doc_id": "doc-d351dc2644fdb606c314890f0871e83f"
  },
  "chunk-193d13b705a8294f63464296c78e020e": {
    "tokens": 1200,
    "content": "(2021), 1–24. [7] Saleema Amershi, Dan Weld, Mihaela Vorvoreanu, Adam Fourney, Besmira Nushi, Penny Collisson, Jina Suh, Shamsi Iqbal, Paul N Bennett, Kori Inkpen, et al. 2019. Guidelines for human-AI interaction. In *Proceedings of the 2019 chi* conference on human factors in computing systems. 1–13. [8] Julia Angwin, Jeff Larson, Surya Mattu, and Lauren Kirchner. 2022. Machine bias. In *Ethics of data and analytics*. Auerbach Publications, 254–264. [9] Amid Ayobi, Katarzyna Stawarz, Dmitri Katz, Paul Marshall, Taku Yamagata, Raúl Santos-Rodríguez, Peter Flach, and Aisling Ann O'Kane. 2021. Machine learning explanations as boundary objects: how AI researchers explain and non-experts perceive machine learning. (2021). [10] Alex Bäuerle, Ángel Alexander Cabrera, Fred Hohman, Megan Maher, David Koski, Xavier Suau, Titus Barik, and Dominik Moritz. 2022. Symphony: Composing interactive interfaces for machine learning. In Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems. 1–14. [11] Eric PS Baumer. 2017. Toward human-centered algorithm design. *Big Data & Society* 4, 2 (2017), 2053951717718854. [12] Avinash Bhat, Austin Coursey, Grace Hu, Sixian Li, Nadia Nahar, Shurui Zhou, Christian Kästner, and Jin LC Guo. 2023. Aspirations and Practice of ML Model Documentation: Moving the Needle with Nudging and Traceability. In Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems. 1–17. [13] Judith M Brown, Gitte Lindgaard, and Robert Biddle. 2011. Collaborative events and shared artefacts: Agile interaction designers and developers working toward common aims. In *2011 Agile Conference*. IEEE, 87–96. Analyzing Collaborative Challenges and Needs of UX Practitioners when Designing with AI/ML 447:23 [14] Carrie J Cai, Samantha Winter, David Steiner, Lauren Wilcox, and Michael Terry. 2021. Onboarding Materials as Cross-functional Boundary Objects for Developing AI Assistants. In Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems. 1–7. [15] Tara Capel and Margot Brereton. 2023. What is Human-Centered about Human-Centered AI? A Map of the Research Landscape. In *Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems* (<conf-loc>, <city>Hamburg</city>, <country>Germany</country>, </conf-loc>) *(CHI '23)*. Association for Computing Machinery, New York, NY, USA, Article 359, 23 pages. https://doi.org/10.1145/3544548.3580959 [16] J Corbin and A Strauss. 2008. Basics of qualitative research. Sage Publications. *Thousand Oaks, CA* (2008). [17] Nigel Cross. 2006. *Designerly ways of knowing*. Springer. [18] Joanna DeFranco-Tommarello and Fadi P Deek. 2002. Collaborative software development: A discussion of problem solving models and groupware technologies. In *Proceedings of the 35th Annual Hawaii International Conference on* System Sciences. IEEE, 568–577. [19] Graham Dove, Kim Halskov, Jodi Forlizzi, and John Zimmerman. 2017. UX design innovation: Challenges for working with machine learning as a design material. In *Proceedings of the 2017 chi conference on human factors in computing* systems. 278–288. [20] Clarence Ellis and Jacques Wainer. 1994. A conceptual model of groupware. In *Proceedings of the 1994 ACM conference* on Computer supported cooperative work. 79–88. [21] Clarence A Ellis, Simon J Gibbs, and Gail Rein. 1991. Groupware: some issues and experiences. *Commun. ACM* 34, 1 (1991), 39–58. [22] KJ Kevin Feng, Tony W Li, and Amy X Zhang. 2023. Understanding Collaborative Practices and Tools of Professional UX Practitioners in Software Organizations. In Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems. 1–20. [23] KJ Kevin Feng and David W McDonald. 2023. Addressing UX Practitioners' Challenges in Designing ML Applications: an Interactive Machine Learning Approach. In *Proceedings of the 28th International Conference on Intelligent User* Interfaces. 337–352. [24] Jennifer Ferreira, Helen Sharp, and Hugh Robinson. 2011. User experience design and agile development: managing cooperation through articulation work. *Software: Practice and Experience* 41, 9 (2011), 963–974. [25] Timnit Gebru, Jamie Morgenstern, Briana Vecchione, Jennifer Wortman Vaughan, Hanna Wallach, Hal Daumé Iii, and Kate Crawford. 2021. Datasheets for datasets. *Commun. ACM* 64, 12 (2021), 86–92. [26] Fabien Girardin and Neal Lathia. 201",
    "chunk_order_index": 15,
    "full_doc_id": "doc-d351dc2644fdb606c314890f0871e83f"
  },
  "chunk-b4d2fd63eeab4329290ed4eb499a4978": {
    "tokens": 1200,
    "content": "Software: Practice and Experience* 41, 9 (2011), 963–974. [25] Timnit Gebru, Jamie Morgenstern, Briana Vecchione, Jennifer Wortman Vaughan, Hanna Wallach, Hal Daumé Iii, and Kate Crawford. 2021. Datasheets for datasets. *Commun. ACM* 64, 12 (2021), 86–92. [26] Fabien Girardin and Neal Lathia. 2017. When user experience designers partner with data scientists. In 2017 AAAI Spring Symposium Series. [27] Saul Greenberg. 1991. Personalizable groupware: Accommodating individual roles and group differences. In Proceedings of the Second European Conference on Computer-Supported Cooperative Work ECSCW'91. Springer, 17–31. [28] Jonathan Grudin. 1988. Why CSCW applications fail: problems in the design and evaluationof organizational interfaces. In *Proceedings of the 1988 ACM conference on Computer-supported cooperative work*. 85–93. [29] Jonathan Grudin. 1994. Groupware and social dynamics: Eight challenges for developers. *Commun. ACM* 37, 1 (1994), 92–105. [30] Carl Gutwin and Saul Greenberg. 1999. The effects of workspace awareness support on the usability of real-time distributed groupware. *ACM Transactions on Computer-Human Interaction (TOCHI)* 6, 3 (1999), 243–281. [31] Carl Gutwin and Saul Greenberg. 2002. A descriptive framework of workspace awareness for real-time groupware. Computer Supported Cooperative Work (CSCW) 11 (2002), 411–446. [32] Amy K Heger, Liz B Marquis, Mihaela Vorvoreanu, Hanna Wallach, and Jennifer Wortman Vaughan. 2022. Understanding Machine Learning Practitioners' Data Documentation Perceptions, Needs, Challenges, and Desiderata. Proceedings of the ACM on Human-Computer Interaction 6, CSCW2 (2022), 1–29. [33] Fred Hohman, Kanit Wongsuphasawat, Mary Beth Kery, and Kayur Patel. 2020. Understanding and visualizing data iteration in machine learning. In *Proceedings of the 2020 CHI conference on human factors in computing systems*. 1–13. [34] Lars Erik Holmquist. 2017. Intelligence on tap: artificial intelligence as a new design material. *interactions* 24, 4 (2017), 28–33. [35] Kenneth Holstein, Jennifer Wortman Vaughan, Hal Daumé III, Miro Dudik, and Hanna Wallach. 2019. Improving fairness in machine learning systems: What do industry practitioners need?. In *Proceedings of the 2019 CHI conference* on human factors in computing systems. 1–16. [36] Matthew K Hong, Adam Fourney, Derek DeBellis, and Saleema Amershi. 2021. Planning for natural language failures with the ai playbook. In *Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems*. 1–11. [37] Yannis Katsis and Christine T. Wolf. 2019. ModelLens: An Interactive System to Support the Model Improvement Practices of Data Science Teams. In *Companion Publication of the 2019 Conference on Computer Supported Cooperative* Work and Social Computing (Austin, TX, USA) *(CSCW '19 Companion)*. Association for Computing Machinery, New York, NY, USA, 9–13. https://doi.org/10.1145/3311957.3359512 [38] Claire Kayacik, Sherol Chen, Signe Noerly, Jess Holbrook, Adam Roberts, and Douglas Eck. 2019. Identifying the intersections: User experience+ research scientist collaboration in a generative machine learning interface. In *Extended* Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems. 1–8. [39] Pascal D König. 2022. Challenges in enabling user control over algorithm-based services. *AI & SOCIETY* (2022), 1–11. [40] Charlotte P Lee. 2007. Boundary negotiating artifacts: Unbinding the routine of boundary objects and embracing chaos in collaborative work. *Computer Supported Cooperative Work (CSCW)* 16 (2007), 307–339. [41] Q Vera Liao, Hariharan Subramonyam, Jennifer Wang, and Jennifer Wortman Vaughan. 2023. Designerly understanding: Information needs for model transparency to support design ideation for AI-powered user experience. In *Proceedings* of the 2023 CHI conference on human factors in computing systems. 1–21. [42] Duri Long and Brian Magerko. 2020. What is AI Literacy? Competencies and Design Considerations. In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems (Honolulu, HI, USA) *(CHI '20)*. Association for Computing Machinery, New York, NY, USA, 1–16. https://doi.org/10.1145/3313831.3376727 [43] Michael Madaio, Lisa Egede, Hariharan Subramonyam, Jennifer Wortman Vaughan, and Hanna Wallach. 2022. Assessing the Fairness of AI Systems: AI Practitioners' Processes, Challenges, and Needs for Support. *Proceedings of the ACM on* Human-Computer Interaction 6, CSCW1 (2022), 1–26. [44] Nol",
    "chunk_order_index": 16,
    "full_doc_id": "doc-d351dc2644fdb606c314890f0871e83f"
  },
  "chunk-0dc2781a55735e52a47c6ffbc9fd8c4d": {
    "tokens": 1200,
    "content": "/10.1145/3313831.3376727 [43] Michael Madaio, Lisa Egede, Hariharan Subramonyam, Jennifer Wortman Vaughan, and Hanna Wallach. 2022. Assessing the Fairness of AI Systems: AI Practitioners' Processes, Challenges, and Needs for Support. *Proceedings of the ACM on* Human-Computer Interaction 6, CSCW1 (2022), 1–26. [44] Nolwenn Maudet, Germán Leiva, Michel Beaudouin-Lafon, and Wendy Mackay. 2017. Design breakdowns: designerdeveloper gaps in representing and interpreting interactive systems. In *Proceedings of the 2017 ACM Conference on* Computer Supported Cooperative Work and Social Computing. 630–641. [45] Margaret Mitchell, Simone Wu, Andrew Zaldivar, Parker Barnes, Lucy Vasserman, Ben Hutchinson, Elena Spitzer, Inioluwa Deborah Raji, and Timnit Gebru. 2019. Model cards for model reporting. In *Proceedings of the conference on* fairness, accountability, and transparency. 220–229. [46] Steven Moore, Q Vera Liao, and Hariharan Subramonyam. 2023. fAIlureNotes: Supporting Designers in Understanding the Limits of AI Models for Computer Vision Tasks. In Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems. 1–19. [47] Golam Mostaeen, Banani Roy, Chanchal Roy, and Kevin Schneider. 2019. Designing for Real-Time Groupware Systems to Support Complex Scientific Data Analysis. *Proc. ACM Hum.-Comput. Interact.* 3, EICS, Article 9 (jun 2019), 28 pages. https://doi.org/10.1145/3331151 [48] Elizamary Nascimento, Anh Nguyen-Duc, Ingrid Sundbø, and Tayana Conte. 2020. Software engineering for artificial intelligence and machine learning software: A systematic literature review. *arXiv preprint arXiv:2011.03751* (2020). [49] Wanda J Orlikowski. 1992. Learning from notes: Organizational issues in groupware implementation. In *Proceedings of* the 1992 ACM conference on Computer-supported cooperative work. 362–369. [50] Fatih Kursat Ozenc, Miso Kim, John Zimmerman, Stephen Oney, and Brad Myers. 2010. How to support designers in getting hold of the immaterial material of software. In *Proceedings of the SIGCHI Conference on Human Factors in* Computing Systems. 2513–2522. [51] Leysia Palen. 1999. Social, individual and technological issues for groupware calendar systems. In *Proceedings of the* SIGCHI conference on Human factors in computing systems. 17–24. [52] Soya Park, April Yi Wang, Ban Kawas, Q Vera Liao, David Piorkowski, and Marina Danilevsky. 2021. Facilitating knowledge sharing from domain experts to data scientists for building nlp models. In *26th International Conference on* Intelligent User Interfaces. 585–596. [53] David Piorkowski, Soya Park, April Yi Wang, Dakuo Wang, Michael Muller, and Felix Portnoy. 2021. How ai developers overcome communication challenges in a multidisciplinary team: A case study. *Proceedings of the ACM on HumanComputer Interaction* 5, CSCW1 (2021), 1–25. [54] David Piorkowski, Inge Vejsbjerg, Owen Cornec, Elizabeth M Daly, and Öznur Alkan. 2023. AIMEE: An Exploratory Study of How Rules Support AI Developers to Explain and Edit Models. *Proceedings of the ACM on Human-Computer* Interaction 7, CSCW2 (2023), 1–25. [55] Mahima Pushkarna, Andrew Zaldivar, and Oddur Kjartansson. 2022. Data cards: Purposeful and transparent dataset documentation for responsible ai. In *Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency*. 1776–1826. [56] Bogdana Rakova, Jingying Yang, Henriette Cramer, and Rumman Chowdhury. 2021. Where responsible AI meets reality: Practitioner perspectives on enablers for shifting organizational practices. *Proceedings of the ACM on Human-Computer* Interaction 5, CSCW1 (2021), 1–23. [57] Samantha Robertson, Zijie J Wang, Dominik Moritz, Mary Beth Kery, and Fred Hohman. 2023. Angler: Helping Machine Translation Practitioners Prioritize Model Improvements. In *Proceedings of the 2023 CHI Conference on Human* Factors in Computing Systems. 1–20. [58] Robert Slagter. 2007. *Groupware*. John Wiley & Sons, Ltd, 16–32. https://doi.org/10.1002/9781118256107.ch2 [59] Susan Leigh Star and James R Griesemer. 1989. Institutional ecology,translations' and boundary objects: Amateurs and professionals in Berkeley's Museum of Vertebrate Zoology, 1907-39. *Social studies of science* 19, 3 (1989), 387–420. Analyzing Collaborative Challenges and Needs of UX Practitioners when Designing with AI/ML 447:25 [60] Hariharan Subramonyam, Jane Im, Colleen Seifert",
    "chunk_order_index": 17,
    "full_doc_id": "doc-d351dc2644fdb606c314890f0871e83f"
  },
  "chunk-baa7177b52e9c7a0a3c0676e12011e6f": {
    "tokens": 1009,
    "content": "James R Griesemer. 1989. Institutional ecology,translations' and boundary objects: Amateurs and professionals in Berkeley's Museum of Vertebrate Zoology, 1907-39. *Social studies of science* 19, 3 (1989), 387–420. Analyzing Collaborative Challenges and Needs of UX Practitioners when Designing with AI/ML 447:25 [60] Hariharan Subramonyam, Jane Im, Colleen Seifert, and Eytan Adar. 2022. Solving separation-of-concerns problems in collaborative design of human-AI systems through leaky abstractions. In *Proceedings of the 2022 CHI Conference on* Human Factors in Computing Systems. 1–21. [61] Hariharan Subramonyam, Colleen Seifert, and Eytan Adar. 2021. Protoai: Model-informed prototyping for ai-powered interfaces. In *26th International Conference on Intelligent User Interfaces*. 48–58. [62] Hariharan Subramonyam, Colleen Seifert, and Eytan Adar. 2021. Towards a process model for co-creating AI experiences. In *Designing Interactive Systems Conference 2021*. 1529–1543. [63] Qiaosi Wang, Michael Madaio, Shaun Kane, Shivani Kapania, Michael Terry, and Lauren Wilcox. 2023. Designing Responsible AI: Adaptations of UX Practice to Meet Responsible AI Challenges. In *Proceedings of the 2023 CHI Conference* on Human Factors in Computing Systems. 1–16. [64] Maximiliane Windl, Sebastian S Feger, Lara Zijlstra, Albrecht Schmidt, and Pawel W Wozniak. 2022. 'It Is Not Always Discovery Time': Four Pragmatic Approaches in Designing AI Systems. In Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems. 1–12. [65] Qian Yang, Justin Cranshaw, Saleema Amershi, Shamsi T Iqbal, and Jaime Teevan. 2019. Sketching nlp: A case study of exploring the right things to design with language intelligence. In *Proceedings of the 2019 CHI Conference on Human* Factors in Computing Systems. 1–12. [66] Qian Yang, Alex Scuito, John Zimmerman, Jodi Forlizzi, and Aaron Steinfeld. 2018. Investigating how experienced UX designers effectively work with machine learning. In *Proceedings of the 2018 designing interactive systems conference*. 585–596. [67] Qian Yang, Aaron Steinfeld, Carolyn Rosé, and John Zimmerman. 2020. Re-examining whether, why, and how humanAI interaction is uniquely difficult to design. In *Proceedings of the 2020 chi conference on human factors in computing* systems. 1–13. [68] Zining Ye, Xinran Yuan, Shaurya Gaur, Aaron Halfaker, Jodi Forlizzi, and Haiyi Zhu. 2021. Wikipedia ORES explorer: Visualizing trade-offs for designing applications with machine learning API. In Designing Interactive Systems Conference 2021. 1554–1565. [69] Nur Yildirim, Alex Kass, Teresa Tung, Connor Upton, Donnacha Costello, Robert Giusti, Sinem Lacin, Sara Lovic, James M O'Neill, Rudi O'Reilly Meehan, et al. 2022. How Experienced Designers of Enterprise Applications Engage AI as a Design Material. In *Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems*. 1–13. [70] Nur Yildirim, Mahima Pushkarna, Nitesh Goyal, Martin Wattenberg, and Fernanda Viégas. 2023. Investigating How Practitioners Use Human-AI Guidelines: A Case Study on the People+ AI Guidebook. In *Proceedings of the 2023 CHI* Conference on Human Factors in Computing Systems. 1–13. [71] Sabah Zdanowska and Alex S Taylor. 2022. A study of UX practitioners roles in designing real-world, enterprise ML systems. In *Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems*. 1–15. [72] Amy X Zhang, Michael Muller, and Dakuo Wang. 2020. How do data science workers collaborate? roles, workflows, and tools. *Proceedings of the ACM on Human-Computer Interaction* 4, CSCW1 (2020), 1–23. Received July 2023; revised January 2024; accepted March 2024",
    "chunk_order_index": 18,
    "full_doc_id": "doc-d351dc2644fdb606c314890f0871e83f"
  }
}